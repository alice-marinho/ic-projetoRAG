

"""
    Classe aplica a interdisiciplinaridade

    :param curso
    :param periodo educacional
    :param disciplina 1
    :param disciplina 2

    :return


"""
from llm import LLMClient
from vectorstore import VectorStoreManager


class Interdisciplina:
    def __init__(
            self,
            curso:str,
            periodo:str,
            disciplinas: list[str]
           # disciplina2: str
    ):
        self.curso = curso
        self.periodo = periodo
        self.disciplinas = disciplinas
        self.vectorstore = VectorStoreManager()

       # self.disciplina2 = disciplina2

    def executar(self):
        print(f"üîç Buscando chunks para:\nCurso: {self.curso}\nPer√≠odo: {self.periodo}\nDisciplinas: {self.disciplinas}")
        chunks_gerais = []

        for comp in self.disciplinas:
            # ‚úÖ Busca textual no conte√∫do, sem filtro de metadados
            docs = self.vectorstore.buscar_chunks_por_texto(
                texto_busca=comp,
                k=10
            )

            if docs:
                texto = "\n".join([doc.page_content for doc in docs])
                chunks_gerais.append((comp, texto))
            else:
                print(f"‚ùå Nenhum chunk encontrado para: {comp}")

        if len(chunks_gerais) < 2:
            print("‚ö†Ô∏è √â necess√°rio pelo menos duas disciplinas com conte√∫do dispon√≠vel.")
            return

        print("\nüí¨ Enviando para a IA...")
        # Aqui voc√™ pode continuar com a l√≥gica de gera√ß√£o ou sugest√£o com IA usando `chunks_gerais`

    # def executar(self):
    #     print(f"üîç Buscando chunks para:\nCurso: {self.curso}\nPer√≠odo: {self.periodo}\nDisciplinas: {self.disciplinas}")
    #     chunks_gerais = []
    #
    #     for comp in self.disciplinas:
    #         docs = self.vectorstore.buscar_chunks_por_metadados(
    #             curso=self.curso,
    #             periodo=self.periodo,
    #             componente=comp,
    #             k=10
    #         )
    #         if docs:
    #             texto = "\n".join([doc.page_content for doc in docs])
    #             chunks_gerais.append((comp, texto))
    #         else:
    #             print(f"‚ùå Nenhum chunk encontrado para: {comp}")
    #
    #     if len(chunks_gerais) < 2:
    #         print("‚ö†Ô∏è √â necess√°rio pelo menos duas disciplinas com conte√∫do dispon√≠vel.")
    #         return
    #
    #     print("\nüí¨ Enviando para a IA...")
    #
    #     prompt = "Com base nos conte√∫dos apresentados abaixo, gere sugest√µes de projetos interdisciplinares contextualizados:\n\n"
    #     for comp, texto in chunks_gerais:
    #         prompt += f"\n\n---\nüìò {comp}:\n{texto}"
    #
    #     resposta = LLMClient().chat(prompt)
    #     print("\nüß† Resposta da IA:\n")
    #     print(resposta)

    def interdisciplinaridade_filtros(self) -> str:
        """
        Busca os chunks das disciplinas no CSV e gera uma proposta interdisciplinar com a LLM.
        """
        dados = self.chunk_service.filtrar_conteudo(
            curso=self.curso,
            periodo=self.periodo,
            componentes=self.disciplinas
        )

        if len(dados) < 2:
            return "‚ö†Ô∏è √â necess√°rio pelo menos duas disciplinas com conte√∫do dispon√≠vel."

        textos = []
        for item in dados:
            nome = item.get("Componente curricular", "Sem nome")
            ementa = item.get("Ementa", "")
            objetivos = item.get("Objetivos", "")
            conteudo = item.get("Conte√∫do Program√°tico", "")

            texto_unico = f"Ementa: {ementa}\nObjetivos: {objetivos}\nConte√∫do: {conteudo}"
            textos.append((nome, texto_unico))

        # Monta prompt
        prompt = f"Curso: {self.curso} | Per√≠odo: {self.periodo}\n\n"
        for nome, conteudo in textos:
            prompt += f"--- {nome} ---\n{conteudo}\n\n"

        prompt += "Com base nesses conte√∫dos, proponha ideias de projetos e atividades interdisciplinares contextualizadas."

        print("\nüí¨ Enviando para a IA...")
        resposta = LLMClient().chat(prompt)
        return resposta
